{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -r cs224u"
      ],
      "metadata": {
        "id": "3LbbL-MLO8iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone --branch \"2022-spring\" https://github.com/cgpotts/cs224u.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFp-ycr4Ovpo",
        "outputId": "f8f9ed12-e747-494e-a04b-54de7a6ae0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs224u'...\n",
            "remote: Enumerating objects: 2328, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 2328 (delta 120), reused 163 (delta 106), pack-reused 2092\u001b[K\n",
            "Receiving objects: 100% (2328/2328), 41.68 MiB | 25.04 MiB/s, done.\n",
            "Resolving deltas: 100% (1419/1419), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd cs224u"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1cc9W3tPe07",
        "outputId": "62197aef-92ff-4b8f-9771-9255f5d076c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cs224u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0d67hlN4qMx"
      },
      "outputs": [],
      "source": [
        "from colors import ColorsCorpusReader\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_color_describer import ContextualColorDescriber\n",
        "from torch_color_describer import create_example_dataset\n",
        "\n",
        "import utils\n",
        "from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL\n",
        "utils.fix_random_seeds()\n",
        "COLORS_SRC_FILENAME = os.path.join(\n",
        "    \"filteredCorpus.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://raw.githubusercontent.com/futurulus/coop-nets/master/behavioralAnalysis/humanOutput/filteredCorpus.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imlczHYLQwo4",
        "outputId": "8251f144-7b67-4d24-da75-b9289c427299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-17 09:32:18--  https://raw.githubusercontent.com/futurulus/coop-nets/master/behavioralAnalysis/humanOutput/filteredCorpus.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9784616 (9.3M) [text/plain]\n",
            "Saving to: ‘filteredCorpus.csv’\n",
            "\n",
            "filteredCorpus.csv  100%[===================>]   9.33M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-03-17 09:32:18 (99.4 MB/s) - ‘filteredCorpus.csv’ saved [9784616/9784616]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_corpus = ColorsCorpusReader(\n",
        "    COLORS_SRC_FILENAME,\n",
        "    word_count=2,\n",
        "    normalize_colors=True)\n",
        "dev_examples = list(dev_corpus.read())\n",
        "# This subset has about one-third the examples of the full corpus:\n",
        "\n",
        "len(dev_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOpru1LXPlPs",
        "outputId": "e65f75d3-078d-4a9f-b1ee-2bf5b3967011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13890"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])"
      ],
      "metadata": {
        "id": "1TmawuoURB72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test = \\\n",
        "    train_test_split(dev_rawcols, dev_texts)"
      ],
      "metadata": {
        "id": "cxaImuo8RDKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_example(s):\n",
        "\n",
        "    # Improve me!\n",
        "\n",
        "    return [START_SYMBOL] + s.split() + [END_SYMBOL]\n",
        "tokenize_example(dev_texts_train[376])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO6uAUCtRHP2",
        "outputId": "2995c059-b145-4e48-d130-197e03b56eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'aqua,', 'teal', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_tokenize_example(func):\n",
        "    s = \"A test string\"\n",
        "    result = func(s)\n",
        "    assert all(isinstance(tok, str) for tok in result), \\\n",
        "        \"The tokenizer must return a list of strings.\"\n",
        "    assert result[0] == START_SYMBOL, \\\n",
        "        \"The tokenizer must add START_SYMBOL as the first token.\"\n",
        "    assert result[-1] == END_SYMBOL, \\\n",
        "        \"The tokenizer must add END_SYMBOL as the final token.\""
      ],
      "metadata": {
        "id": "6hsigQhKRNUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    test_tokenize_example(tokenize_example)"
      ],
      "metadata": {
        "id": "qSEeMdHXRTdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seqs_train = [tokenize_example(s) for s in dev_texts_train]\n",
        "\n",
        "dev_seqs_test = [tokenize_example(s) for s in dev_texts_test]"
      ],
      "metadata": {
        "id": "hbNnsFL-RV_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_vocab = sorted({w for toks in dev_seqs_train for w in toks})\n",
        "\n",
        "dev_vocab += [UNK_SYMBOL]"
      ],
      "metadata": {
        "id": "4JTQnSrRRY3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dev_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9X7t7zMRayU",
        "outputId": "362f95df-767d-46e7-80fd-de84b42f8050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1439"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def represent_color_context(colors):\n",
        "\n",
        "    # Improve me!\n",
        "\n",
        "    return [represent_color(color) for color in colors]\n",
        "\n",
        "\n",
        "def represent_color(color):\n",
        "\n",
        "    # Improve me!\n",
        "\n",
        "    return color"
      ],
      "metadata": {
        "id": "Cp-NUe3yRen5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "represent_color_context(dev_rawcols_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG2rpOaNRgcA",
        "outputId": "b816f72b-ee4f-4146-fe17-ee9497f87107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.19444444444444445, 0.5, 0.11],\n",
              " [0.7472222222222222, 0.5, 0.27],\n",
              " [0.2722222222222222, 0.5, 0.73]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_represent_color_context(func):\n",
        "    \"\"\"`func` should be `represent_color_context`\"\"\"\n",
        "    example = [\n",
        "        [0.786, 0.58, 0.87],\n",
        "        [0.689, 0.44, 0.92],\n",
        "        [0.628, 0.32, 0.81]]\n",
        "    result = func(example)\n",
        "    assert len(result) == len(example), \\\n",
        "        (\"Color context representations need to represent each color \"\n",
        "         \"separately. (We assume the final color is the target.)\")\n",
        "    for i, color in enumerate(result):\n",
        "        assert all(isinstance(x, float) for x in color), \\\n",
        "            (\"All color representations should be lists of floats. \"\n",
        "             \"Color {} is {}\".format(i, color))\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    test_represent_color_context(represent_color_context)"
      ],
      "metadata": {
        "id": "0hhQIdWzRipt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_cols_train = [represent_color_context(colors) for colors in dev_rawcols_train]\n",
        "\n",
        "dev_cols_test = [represent_color_context(colors) for colors in dev_rawcols_test]"
      ],
      "metadata": {
        "id": "5NP_bpgVRlJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mod = ContextualColorDescriber(\n",
        "    dev_vocab,\n",
        "    early_stopping=True)\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    %time _ = dev_mod.fit(dev_cols_train, dev_seqs_train)\n",
        "else:\n",
        "    dev_mod.fit(dev_cols_train, dev_seqs_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4lTVY-c4RnSU",
        "outputId": "69391e8c-ac24-425b-cc74-eee8ffd032e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/content/cs224u/torch_model_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mepoch_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = dev_mod.evaluate(dev_cols_test, dev_seqs_test)\n",
        "evaluation.keys()\n",
        "evaluation['listener_accuracy']\n",
        "dev_mod.listener_accuracy(dev_cols_test, dev_seqs_test)\n",
        "evaluation['corpus_bleu']\n",
        "bleu, predicted_utterances = dev_mod.corpus_bleu(dev_cols_test, dev_seqs_test)\n",
        "\n",
        "bleu\n",
        "evaluation['target_index'][: 5]\n",
        "evaluation['predicted_index'][: 5]\n",
        "evaluation['predicted_utterance'][: 5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdZcgF20Rr25",
        "outputId": "af912443-a783-4a8f-ce96-6e1e14fc3e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/cs224u/torch_color_describer.py:91: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  color_seqs = torch.FloatTensor(color_seqs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<s>',\n",
              "  'mustard',\n",
              "  'tan',\n",
              "  'puke',\n",
              "  'Middle',\n",
              "  'yep!',\n",
              "  'ya!',\n",
              "  'thinkg',\n",
              "  'grreen',\n",
              "  'Box',\n",
              "  'different',\n",
              "  'perfect!',\n",
              "  'brigther',\n",
              "  'mustard',\n",
              "  'muted',\n",
              "  'seal',\n",
              "  'those',\n",
              "  'rude',\n",
              "  'purple,',\n",
              "  'oh'],\n",
              " ['<s>',\n",
              "  'mustard',\n",
              "  'tan',\n",
              "  'puke',\n",
              "  'Middle',\n",
              "  'yep!',\n",
              "  'ya!',\n",
              "  'thinkg',\n",
              "  'grreen',\n",
              "  'Box',\n",
              "  'different',\n",
              "  'perfect!',\n",
              "  'brigther',\n",
              "  'mustard',\n",
              "  'muted',\n",
              "  'seal',\n",
              "  'those',\n",
              "  'rude',\n",
              "  'purple,',\n",
              "  'oh'],\n",
              " ['<s>',\n",
              "  'mustard',\n",
              "  'tan',\n",
              "  'puke',\n",
              "  'Middle',\n",
              "  'yep!',\n",
              "  'ya!',\n",
              "  'thinkg',\n",
              "  'grreen',\n",
              "  'Box',\n",
              "  'different',\n",
              "  'perfect!',\n",
              "  'brigther',\n",
              "  'mustard',\n",
              "  'muted',\n",
              "  'seal',\n",
              "  'those',\n",
              "  'rude',\n",
              "  'purple,',\n",
              "  'oh'],\n",
              " ['<s>',\n",
              "  'mustard',\n",
              "  'tan',\n",
              "  'puke',\n",
              "  'Middle',\n",
              "  'yep!',\n",
              "  'ya!',\n",
              "  'thinkg',\n",
              "  'grreen',\n",
              "  'Box',\n",
              "  'different',\n",
              "  'perfect!',\n",
              "  'brigther',\n",
              "  'mustard',\n",
              "  'muted',\n",
              "  'seal',\n",
              "  'those',\n",
              "  'rude',\n",
              "  'purple,',\n",
              "  'oh'],\n",
              " ['<s>',\n",
              "  'mustard',\n",
              "  'tan',\n",
              "  'puke',\n",
              "  'Middle',\n",
              "  'yep!',\n",
              "  'ya!',\n",
              "  'thinkg',\n",
              "  'grreen',\n",
              "  'Box',\n",
              "  'different',\n",
              "  'perfect!',\n",
              "  'brigther',\n",
              "  'mustard',\n",
              "  'muted',\n",
              "  'seal',\n",
              "  'those',\n",
              "  'rude',\n",
              "  'purple,',\n",
              "  'oh']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mod.predict(dev_cols_test[: 1])\n",
        "dev_seqs_test[: 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef2E9-ruRvHx",
        "outputId": "405ba3e6-47e0-4cb4-c8e4-cc97826387b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<s>', 'right', 'side', '###', 'purple', 'pinkish', '</s>']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_HOME = os.path.join('data', 'glove.6B')\n",
        "def create_glove_embedding(vocab, glove_base_filename='glove.6B.50d.txt'):\n",
        "    pass\n",
        "    # Use `utils.glove2dict` to read in the GloVe file:\n",
        "\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "    # Use `utils.create_pretrained_embedding` to create the embedding.\n",
        "    # This function will, by default, ensure that START_TOKEN,\n",
        "    # END_TOKEN, and UNK_TOKEN are included in the embedding.\n",
        "\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "    # Be sure to return the embedding you create as well as the\n",
        "    # vocabulary returned by `utils.create_pretrained_embedding`,\n",
        "    # which is likely to have been modified from the input `vocab`.\n",
        "\n",
        "    ##### YOUR CODE HERE\n",
        "def test_create_glove_embedding(func):\n",
        "    vocab = ['NLU', 'is', 'the', 'future', '.', '$UNK', '<s>', '</s>']\n",
        "    glove_embedding, glove_vocab = func(vocab, 'glove.6B.50d.txt')\n",
        "    assert isinstance(glove_embedding, np.ndarray), \\\n",
        "        \"Expected embedding type {}; got {}\".format(\n",
        "        glove_embedding.__class__.__name__, glove_embedding.__class__.__name__)\n",
        "    assert glove_embedding.shape == (8, 50), \\\n",
        "        \"Expected embedding shape (8, 50); got {}\".format(glove_embedding.shape)\n",
        "    assert glove_vocab == vocab, \\\n",
        "        \"Expected vocab {}; got {}\".format(vocab, glove_vocab)\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    test_create_glove_embedding(create_glove_embedding)"
      ],
      "metadata": {
        "id": "UP8UlK7RR7Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_glove_embedding, dev_glove_vocab = create_glove_embedding(dev_vocab)\n",
        "len(dev_vocab)\n",
        "len(dev_glove_vocab)\n",
        "dev_mod_glove = ContextualColorDescriber(\n",
        "    dev_glove_vocab,\n",
        "    embedding=dev_glove_embedding,\n",
        "    early_stopping=True)\n",
        "_ = dev_mod_glove.fit(dev_cols_train, dev_seqs_train)\n",
        "dev_mod_glove.listener_accuracy(dev_cols_test, dev_seqs_test)"
      ],
      "metadata": {
        "id": "qYto-OpHxuJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_color_describer import Decoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ColorContextDecoder(Decoder):\n",
        "    def __init__(self, color_dim, *args, **kwargs):\n",
        "        self.color_dim = color_dim\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # Fix the `self.rnn` attribute:\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=self.embed_dim+self.color_dim,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            batch_first=True)\n",
        "\n",
        "\n",
        "    def get_embeddings(self, word_seqs, target_colors=None):\n",
        "        \"\"\"\n",
        "        You can assume that `target_colors` is a tensor of shape\n",
        "        (m, n), where m is the length of the batch (same as\n",
        "        `word_seqs.shape[0]`) and n is the dimensionality of the\n",
        "        color representations the model is using. The goal is\n",
        "        to attached each color vector i to each of the tokens in\n",
        "        the ith sequence of (the embedded version of) `word_seqs`.\n",
        "\n",
        "        \"\"\"\n",
        "        ##### YOUR CODE HERE\n",
        "        ret=torch.zeros((word_seqs.shape[0],word_seqs.shape[1],self.embed_dim+self.color_dim))\n",
        "        for i in range(word_seqs.shape[0]):\n",
        "          for j in range(word_seqs.shape[1]):\n",
        "            # print(self.embedding(torch.tensor(word_seqs[i,j])))\n",
        "            # print(target_colors[i])\n",
        "            ret[i,j]=torch.cat([self.embedding(torch.tensor(word_seqs[i,j])),target_colors[i]])\n",
        "        return ret"
      ],
      "metadata": {
        "id": "1-wiMst6xxGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_get_embeddings(decoder_class):\n",
        "    \"\"\"\n",
        "    It's assumed that the input to this will be `ColorContextDecoder`.\n",
        "    You pass in the class, and the function initalizes it with the test\n",
        "    parameters.\n",
        "    \"\"\"\n",
        "    dec = decoder_class(\n",
        "        color_dim=3,   # For these, we mainly want *different*\n",
        "        vocab_size=10, # dimensions so that we reliably get\n",
        "        embed_dim=4,   # dimensionality errors if something\n",
        "        hidden_dim=5)  # isn't working.\n",
        "\n",
        "    # This step just changes the embedding to one with values\n",
        "    # that are easy to inspect and definitely will not change\n",
        "    # between runs:\n",
        "    dec.embedding = nn.Embedding.from_pretrained(\n",
        "        torch.FloatTensor([\n",
        "            [10, 11, 12, 13],\n",
        "            [14, 15, 16, 17],\n",
        "            [18, 19, 20, 21]]))\n",
        "\n",
        "    # These are the incoming sequences -- lists of indices\n",
        "    # into the rows of `dec.embedding`:\n",
        "    word_seqs = torch.tensor([\n",
        "        [0,1,2],\n",
        "        [2,0,1]])\n",
        "\n",
        "    # Target colors as small floats that will be easy to track:\n",
        "    target_colors = torch.tensor([\n",
        "        [0.1, 0.2, 0.3],\n",
        "        [0.7, 0.8, 0.9]])\n",
        "\n",
        "    # The desired return value: one list of tensors for each of\n",
        "    # the two sequences in `word_seqs`. Each index is replaced\n",
        "    # with its vector from `dec.embedding` and has the\n",
        "    # corrresponding color from `target_colors` appended to it.\n",
        "    expected = torch.tensor([\n",
        "        [[10., 11., 12., 13.,  0.1,  0.2,  0.3],\n",
        "         [14., 15., 16., 17.,  0.1,  0.2,  0.3],\n",
        "         [18., 19., 20., 21.,  0.1,  0.2,  0.3]],\n",
        "\n",
        "        [[18., 19., 20., 21.,  0.7,  0.8,  0.9],\n",
        "         [10., 11., 12., 13.,  0.7,  0.8,  0.9],\n",
        "         [14., 15., 16., 17.,  0.7,  0.8,  0.9]]])\n",
        "\n",
        "    result = dec.get_embeddings(word_seqs, target_colors=target_colors)\n",
        "\n",
        "    assert expected.shape == result.shape, \\\n",
        "        \"Expected shape {}; got shape {}\".format(expected.shape, result.shape)\n",
        "\n",
        "    assert torch.all(expected.eq(result)), \\\n",
        "        (\"Your result has the desired shape but the values aren't correct. \"\n",
        "         \"Here's what your function creates; compare it with `expected` \"\n",
        "         \"from the test:\\n{}\".format(result))"
      ],
      "metadata": {
        "id": "49x2G7scx636"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    test_get_embeddings(ColorContextDecoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P6kcHqkx7t5",
        "outputId": "49092323-2a10-40cd-ee6d-13fdbeb9b66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-37e5daaff26c>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  ret[i,j]=torch.cat([self.embedding(torch.tensor(word_seqs[i,j])),target_colors[i]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_color_describer import EncoderDecoder\n",
        "\n",
        "class ColorizedEncoderDecoder(EncoderDecoder):\n",
        "\n",
        "    def forward(self,\n",
        "            color_seqs,\n",
        "            word_seqs,\n",
        "            seq_lengths=None,\n",
        "            hidden=None,\n",
        "            targets=None):\n",
        "        if hidden is None:\n",
        "            hidden = self.encoder(color_seqs)\n",
        "\n",
        "        # Extract the target colors from `color_seqs` and\n",
        "        # feed them to the decoder, which already has a\n",
        "        # `target_colors` keyword.\n",
        "\n",
        "        ##### YOUR CODE HERE\n",
        "        # print(color_seqs[:,-1])\n",
        "        # print(word_seqs)\n",
        "        output,hidden = self.decoder(word_seqs,target_colors=color_seqs[:,-1],seq_lengths=seq_lengths,hidden=hidden)\n",
        "\n",
        "\n",
        "        # Your decoder will return `output, hidden` pairs; the\n",
        "        # following will handle the two return situations that\n",
        "        # the code needs to consider -- training and prediction.\n",
        "        if self.training:\n",
        "            return output\n",
        "        else:\n",
        "            return output, hidden"
      ],
      "metadata": {
        "id": "8d7Au7uYx_ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_color_describer import Encoder\n",
        "\n",
        "class ColorizedInputDescriber(ContextualColorDescriber):\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        # We didn't modify the encoder, so this is\n",
        "        # just copied over from the original:\n",
        "        encoder = Encoder(\n",
        "            color_dim=self.color_dim,\n",
        "            hidden_dim=self.hidden_dim)\n",
        "\n",
        "        # Use your `ColorContextDecoder`, making sure\n",
        "        # to pass in all the keyword arguments coming\n",
        "        # from `ColorizedInputDescriber`:\n",
        "\n",
        "        ##### YOUR CODE HERE\n",
        "        decoder = ColorContextDecoder(\n",
        "            color_dim=self.color_dim,\n",
        "            vocab_size=self.vocab_size,\n",
        "            embed_dim=self.embed_dim,\n",
        "            hidden_dim=self.hidden_dim)\n",
        "\n",
        "\n",
        "        # Return a `ColorizedEncoderDecoder` that uses\n",
        "        # your encoder and decoder:\n",
        "        return ColorizedEncoderDecoder(encoder,decoder)\n",
        "        ##### YOUR CODE HERE"
      ],
      "metadata": {
        "id": "h1wtuXzSyCmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_full_system(describer_class):\n",
        "    toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(\n",
        "        group_size=50, vec_dim=2)\n",
        "\n",
        "    toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
        "        train_test_split(toy_color_seqs, toy_word_seqs)\n",
        "\n",
        "    toy_mod = describer_class(toy_vocab)\n",
        "\n",
        "    _ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)\n",
        "\n",
        "    acc = toy_mod.listener_accuracy(toy_color_seqs_test, toy_word_seqs_test)\n",
        "\n",
        "    return acc\n",
        "test_full_system(ColorizedInputDescriber)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adK2hxC8yF2E",
        "outputId": "235412cf-75fd-496b-de7e-f6dcd5a4b9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-16cd3293f7fa>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  ret[i,j]=torch.cat([self.embedding(torch.tensor(word_seqs[i,j])),target_colors[i]])\n",
            "Finished epoch 1000 of 1000; error is 0.11100998520851135"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_original_system(trained_model, color_seqs_test, texts_test):\n",
        "    \"\"\"\n",
        "    Feel free to modify this code to accommodate the needs of\n",
        "    your system. Just keep in mind that it will get raw corpus\n",
        "    examples as inputs for the bake-off.\n",
        "\n",
        "    \"\"\"\n",
        "    # `word_seqs_test` is a list of strings, so tokenize each of\n",
        "    # its elements:\n",
        "    tok_seqs = [tokenize_example(s) for s in texts_test]\n",
        "\n",
        "    col_seqs = [represent_color_context(colors)\n",
        "                for colors in color_seqs_test]\n",
        "\n",
        "\n",
        "    # Optionally include other preprocessing steps here. Note:\n",
        "    # DO NOT RETRAIN YOUR MODEL AS PART OF THIS EVALUATION!\n",
        "    # It's a tempting step, but it's a mistake and will get\n",
        "    # you disqualified!\n",
        "\n",
        "    # The following core score calculations are required:\n",
        "    evaluation = trained_model.evaluate(col_seqs, tok_seqs)\n",
        "\n",
        "    return evaluation"
      ],
      "metadata": {
        "id": "3lNLfWwzypSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_evaluation = evaluate_original_system(dev_mod, dev_rawcols_test, dev_texts_test)\n",
        "my_evaluation['listener_accuracy']\n",
        "# my_evaluation['corpus_bleu']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4H-QX5-yrE1",
        "outputId": "08bfcd68-5b43-4099-b1da-1de8852205f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33170169881946443"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}